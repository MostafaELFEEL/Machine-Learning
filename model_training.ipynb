{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# CNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2453\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import torch as t\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import cv2\n",
        "import os\n",
        "import torchvision.transforms as transforms\n",
        "from sklearn.model_selection import train_test_split\n",
        "import torchvision\n",
        "import csv\n",
        "####################################\n",
        "def imshow(img):\n",
        "    plt.imshow(cv2.cvtColor(np.transpose(np.array(img),(1,2,0)),cv2.COLOR_RGB2BGR))\n",
        "###################################\n",
        "###################################\n",
        "#hyperparameters\n",
        "epochs=10\n",
        "batch_size=64\n",
        "learning_rate=0.001\n",
        "####################################\n",
        "#load csv and remove the path\n",
        "with open('Data\\driving_log.csv', newline='') as csvfile:\n",
        "    data = list(csv.reader(csvfile))\n",
        "####################################\n",
        "for i in range(len(data)):\n",
        "    for j in range(3):\n",
        "        data[i][j]=data[i][j].replace('C:\\\\Users\\\\mosta\\\\Downloads\\\\AI racing team\\\\beta_simulator_windows\\\\Data\\\\IMG\\\\','')\n",
        "####################################\n",
        "#load images in data\n",
        "directory_images=\"Data\\IMG\"\n",
        "print(len(data))\n",
        "for i in range(len(data)):\n",
        "    for j in range(3):\n",
        "        data[i][j]=transforms.ToTensor()(cv2.imread(directory_images+\"\\\\\"+data[i][j]))\n",
        "        #print(data[i][j].shape)\n",
        "###################################\n",
        "#tranform column 3,4,5,6 to tensors\n",
        "for i in range(len(data)):\n",
        "    for j in range(3,7):\n",
        "        data[i][j]=t.tensor(float(data[i][j]))  \n",
        "###################################\n",
        "#split data to train,test\n",
        "train_data, test_data = train_test_split(data, test_size=0.2, random_state=42)\n",
        "###################################\n",
        "train_data=t.utils.data.DataLoader(train_data,batch_size=batch_size,shuffle=True)\n",
        "test_data=t.utils.data.DataLoader(test_data,batch_size=batch_size,shuffle=True)\n",
        "###################################\n",
        "\n",
        "class ConvNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "        self.conv1=nn.Conv2d(3,64,7)\n",
        "        self.conv2=nn.Conv2d(64,64,5)\n",
        "        self.conv3=nn.Conv2d(64,64,3)\n",
        "        self.pool=nn.MaxPool2d(2,2)\n",
        "\n",
        "\n",
        "        self.fc1=nn.Linear(64*17*37,128)\n",
        "        self.fc2=nn.Linear(128,2)\n",
        "\n",
        "    def forward(self,x):\n",
        "        # N,3,160,320\n",
        "        #print(x.shape)\n",
        "        x=self.pool(F.relu(self.conv1(x)))    # N,64,77,157\n",
        "        #print(x.shape)\n",
        "\n",
        "        x=self.pool(F.relu(self.conv2(x)))  # N 64,36,76\n",
        "        #print(x.shape)\n",
        "\n",
        "        x=self.pool(F.relu(self.conv3(x)))  # N,64,17,37\n",
        "        #print(x.shape)\n",
        "\n",
        "        x=x.view(-1,64*17*37)     # N,64*17*37\n",
        "        #print(x.shape)\n",
        "\n",
        "        x=F.relu(self.fc1(x))    # N,128\n",
        "        #print(x.shape)\n",
        "        \n",
        "        x=self.fc2(x)            # N,2\n",
        "        #print(x.shape)\n",
        "        return x\n",
        "###################################\n",
        "class CustomCNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CustomCNN, self).__init__()\n",
        "        # Define the layers for your CNN architecture\n",
        "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=16, kernel_size=3, stride=1, padding=1)\n",
        "        self.relu1 = nn.ReLU()\n",
        "        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "        self.conv2 = nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3, stride=1, padding=1)\n",
        "        self.relu2 = nn.ReLU()\n",
        "        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "        self.fc1 = nn.Linear(32 * 40 * 80, 64)  # Adjust the input size based on your image dimensions\n",
        "        self.relu3 = nn.ReLU()\n",
        "        self.fc2 = nn.Linear(64, 2)  # Output two values\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Define the forward pass of your model\n",
        "        #N,3,160,320\n",
        "        x = self.pool1(self.relu1(self.conv1(x))) # N,16,80,160\n",
        "        x = self.pool2(self.relu2(self.conv2(x))) # N,32,40,80\n",
        "        x = x.view(-1,32*40*80)  # Flatten the feature maps  #N,32*40*80\n",
        "        x = self.relu3(self.fc1(x)) # N,64\n",
        "        x = self.fc2(x) # N,2\n",
        "        return x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[1] loss: 0.011\n",
            "[1] loss: 0.377\n",
            "[1] loss: 0.383\n",
            "[1] loss: 0.387\n",
            "[1] loss: 0.397\n",
            "[1] loss: 0.400\n",
            "[1] loss: 0.406\n",
            "[1] loss: 0.412\n",
            "[1] loss: 0.416\n",
            "[1] loss: 0.419\n",
            "[1] loss: 0.425\n",
            "[1] loss: 0.428\n",
            "[1] loss: 0.431\n",
            "[1] loss: 0.434\n",
            "[1] loss: 0.438\n",
            "[1] loss: 0.441\n",
            "[1] loss: 0.445\n",
            "[1] loss: 0.448\n",
            "[1] loss: 0.450\n",
            "[1] loss: 0.452\n",
            "[1] loss: 0.457\n",
            "[1] loss: 0.460\n",
            "[1] loss: 0.463\n",
            "[1] loss: 0.465\n",
            "[1] loss: 0.469\n",
            "[1] loss: 0.472\n",
            "[1] loss: 0.474\n",
            "[1] loss: 0.477\n",
            "[1] loss: 0.479\n",
            "[1] loss: 0.482\n",
            "[1] loss: 0.485\n",
            "[2] loss: 0.002\n",
            "[2] loss: 0.005\n",
            "[2] loss: 0.007\n",
            "[2] loss: 0.009\n",
            "[2] loss: 0.011\n",
            "[2] loss: 0.013\n",
            "[2] loss: 0.015\n",
            "[2] loss: 0.017\n",
            "[2] loss: 0.020\n",
            "[2] loss: 0.022\n",
            "[2] loss: 0.024\n",
            "[2] loss: 0.025\n",
            "[2] loss: 0.028\n",
            "[2] loss: 0.030\n",
            "[2] loss: 0.032\n",
            "[2] loss: 0.034\n",
            "[2] loss: 0.035\n",
            "[2] loss: 0.037\n",
            "[2] loss: 0.039\n",
            "[2] loss: 0.040\n",
            "[2] loss: 0.042\n",
            "[2] loss: 0.044\n",
            "[2] loss: 0.046\n",
            "[2] loss: 0.047\n",
            "[2] loss: 0.049\n",
            "[2] loss: 0.051\n",
            "[2] loss: 0.052\n",
            "[2] loss: 0.054\n",
            "[2] loss: 0.055\n",
            "[2] loss: 0.056\n",
            "[2] loss: 0.058\n",
            "[3] loss: 0.001\n",
            "[3] loss: 0.003\n",
            "[3] loss: 0.003\n",
            "[3] loss: 0.004\n",
            "[3] loss: 0.006\n",
            "[3] loss: 0.007\n",
            "[3] loss: 0.008\n",
            "[3] loss: 0.009\n",
            "[3] loss: 0.010\n",
            "[3] loss: 0.012\n",
            "[3] loss: 0.013\n",
            "[3] loss: 0.014\n",
            "[3] loss: 0.016\n",
            "[3] loss: 0.017\n",
            "[3] loss: 0.018\n",
            "[3] loss: 0.019\n",
            "[3] loss: 0.020\n",
            "[3] loss: 0.021\n",
            "[3] loss: 0.022\n",
            "[3] loss: 0.023\n",
            "[3] loss: 0.024\n",
            "[3] loss: 0.025\n",
            "[3] loss: 0.027\n",
            "[3] loss: 0.028\n",
            "[3] loss: 0.029\n",
            "[3] loss: 0.030\n",
            "[3] loss: 0.031\n",
            "[3] loss: 0.032\n",
            "[3] loss: 0.033\n",
            "[3] loss: 0.034\n",
            "[3] loss: 0.035\n",
            "[4] loss: 0.001\n",
            "[4] loss: 0.001\n",
            "[4] loss: 0.002\n",
            "[4] loss: 0.003\n",
            "[4] loss: 0.004\n",
            "[4] loss: 0.005\n",
            "[4] loss: 0.006\n",
            "[4] loss: 0.007\n",
            "[4] loss: 0.008\n",
            "[4] loss: 0.009\n",
            "[4] loss: 0.010\n",
            "[4] loss: 0.011\n",
            "[4] loss: 0.011\n",
            "[4] loss: 0.012\n",
            "[4] loss: 0.013\n",
            "[4] loss: 0.014\n",
            "[4] loss: 0.015\n",
            "[4] loss: 0.016\n",
            "[4] loss: 0.017\n",
            "[4] loss: 0.018\n",
            "[4] loss: 0.018\n",
            "[4] loss: 0.019\n",
            "[4] loss: 0.020\n",
            "[4] loss: 0.021\n",
            "[4] loss: 0.022\n",
            "[4] loss: 0.023\n",
            "[4] loss: 0.024\n",
            "[4] loss: 0.025\n",
            "[4] loss: 0.025\n",
            "[4] loss: 0.026\n",
            "[4] loss: 0.027\n",
            "[5] loss: 0.001\n",
            "[5] loss: 0.002\n",
            "[5] loss: 0.003\n",
            "[5] loss: 0.004\n",
            "[5] loss: 0.005\n",
            "[5] loss: 0.006\n",
            "[5] loss: 0.006\n",
            "[5] loss: 0.007\n",
            "[5] loss: 0.008\n",
            "[5] loss: 0.009\n",
            "[5] loss: 0.009\n",
            "[5] loss: 0.010\n",
            "[5] loss: 0.010\n",
            "[5] loss: 0.011\n",
            "[5] loss: 0.012\n",
            "[5] loss: 0.013\n",
            "[5] loss: 0.014\n",
            "[5] loss: 0.015\n",
            "[5] loss: 0.016\n",
            "[5] loss: 0.017\n",
            "[5] loss: 0.018\n",
            "[5] loss: 0.019\n",
            "[5] loss: 0.020\n",
            "[5] loss: 0.021\n",
            "[5] loss: 0.022\n",
            "[5] loss: 0.022\n",
            "[5] loss: 0.023\n",
            "[5] loss: 0.024\n",
            "[5] loss: 0.025\n",
            "[5] loss: 0.025\n",
            "[5] loss: 0.026\n",
            "[6] loss: 0.001\n",
            "[6] loss: 0.001\n",
            "[6] loss: 0.002\n",
            "[6] loss: 0.003\n",
            "[6] loss: 0.004\n",
            "[6] loss: 0.004\n",
            "[6] loss: 0.005\n",
            "[6] loss: 0.006\n",
            "[6] loss: 0.006\n",
            "[6] loss: 0.007\n",
            "[6] loss: 0.008\n",
            "[6] loss: 0.009\n",
            "[6] loss: 0.010\n",
            "[6] loss: 0.011\n",
            "[6] loss: 0.012\n",
            "[6] loss: 0.013\n",
            "[6] loss: 0.014\n",
            "[6] loss: 0.014\n",
            "[6] loss: 0.015\n",
            "[6] loss: 0.016\n",
            "[6] loss: 0.017\n",
            "[6] loss: 0.017\n",
            "[6] loss: 0.018\n",
            "[6] loss: 0.019\n",
            "[6] loss: 0.019\n",
            "[6] loss: 0.020\n",
            "[6] loss: 0.020\n",
            "[6] loss: 0.021\n",
            "[6] loss: 0.022\n",
            "[6] loss: 0.022\n",
            "[6] loss: 0.023\n",
            "[7] loss: 0.001\n",
            "[7] loss: 0.001\n",
            "[7] loss: 0.002\n",
            "[7] loss: 0.003\n",
            "[7] loss: 0.003\n",
            "[7] loss: 0.004\n",
            "[7] loss: 0.004\n",
            "[7] loss: 0.005\n",
            "[7] loss: 0.006\n",
            "[7] loss: 0.007\n",
            "[7] loss: 0.007\n",
            "[7] loss: 0.009\n",
            "[7] loss: 0.009\n",
            "[7] loss: 0.010\n",
            "[7] loss: 0.011\n",
            "[7] loss: 0.012\n",
            "[7] loss: 0.012\n",
            "[7] loss: 0.012\n",
            "[7] loss: 0.013\n",
            "[7] loss: 0.014\n",
            "[7] loss: 0.015\n",
            "[7] loss: 0.016\n",
            "[7] loss: 0.016\n",
            "[7] loss: 0.017\n",
            "[7] loss: 0.018\n",
            "[7] loss: 0.018\n",
            "[7] loss: 0.019\n",
            "[7] loss: 0.020\n",
            "[7] loss: 0.020\n",
            "[7] loss: 0.021\n",
            "[7] loss: 0.021\n",
            "[8] loss: 0.001\n",
            "[8] loss: 0.002\n",
            "[8] loss: 0.002\n",
            "[8] loss: 0.003\n",
            "[8] loss: 0.003\n",
            "[8] loss: 0.004\n",
            "[8] loss: 0.005\n",
            "[8] loss: 0.005\n",
            "[8] loss: 0.006\n",
            "[8] loss: 0.007\n",
            "[8] loss: 0.008\n",
            "[8] loss: 0.008\n",
            "[8] loss: 0.009\n",
            "[8] loss: 0.009\n",
            "[8] loss: 0.010\n",
            "[8] loss: 0.010\n",
            "[8] loss: 0.011\n",
            "[8] loss: 0.012\n",
            "[8] loss: 0.013\n",
            "[8] loss: 0.013\n",
            "[8] loss: 0.014\n",
            "[8] loss: 0.015\n",
            "[8] loss: 0.015\n",
            "[8] loss: 0.016\n",
            "[8] loss: 0.017\n",
            "[8] loss: 0.017\n",
            "[8] loss: 0.018\n",
            "[8] loss: 0.018\n",
            "[8] loss: 0.019\n",
            "[8] loss: 0.019\n",
            "[8] loss: 0.020\n",
            "[9] loss: 0.000\n",
            "[9] loss: 0.001\n",
            "[9] loss: 0.002\n",
            "[9] loss: 0.002\n",
            "[9] loss: 0.003\n",
            "[9] loss: 0.004\n",
            "[9] loss: 0.005\n",
            "[9] loss: 0.005\n",
            "[9] loss: 0.006\n",
            "[9] loss: 0.007\n",
            "[9] loss: 0.008\n",
            "[9] loss: 0.008\n",
            "[9] loss: 0.009\n",
            "[9] loss: 0.009\n",
            "[9] loss: 0.010\n",
            "[9] loss: 0.011\n",
            "[9] loss: 0.012\n",
            "[9] loss: 0.012\n",
            "[9] loss: 0.013\n",
            "[9] loss: 0.013\n",
            "[9] loss: 0.014\n",
            "[9] loss: 0.015\n",
            "[9] loss: 0.015\n",
            "[9] loss: 0.016\n",
            "[9] loss: 0.017\n",
            "[9] loss: 0.017\n",
            "[9] loss: 0.018\n",
            "[9] loss: 0.018\n",
            "[9] loss: 0.019\n",
            "[9] loss: 0.020\n",
            "[9] loss: 0.020\n",
            "[10] loss: 0.001\n",
            "[10] loss: 0.002\n",
            "[10] loss: 0.002\n",
            "[10] loss: 0.003\n",
            "[10] loss: 0.004\n",
            "[10] loss: 0.004\n",
            "[10] loss: 0.005\n",
            "[10] loss: 0.006\n",
            "[10] loss: 0.006\n",
            "[10] loss: 0.007\n",
            "[10] loss: 0.007\n",
            "[10] loss: 0.008\n",
            "[10] loss: 0.008\n",
            "[10] loss: 0.009\n",
            "[10] loss: 0.009\n",
            "[10] loss: 0.010\n",
            "[10] loss: 0.010\n",
            "[10] loss: 0.011\n",
            "[10] loss: 0.012\n",
            "[10] loss: 0.012\n",
            "[10] loss: 0.013\n",
            "[10] loss: 0.013\n",
            "[10] loss: 0.014\n",
            "[10] loss: 0.015\n",
            "[10] loss: 0.015\n",
            "[10] loss: 0.016\n",
            "[10] loss: 0.016\n",
            "[10] loss: 0.016\n",
            "[10] loss: 0.017\n",
            "[10] loss: 0.018\n",
            "[10] loss: 0.019\n",
            "Finished Training\n"
          ]
        }
      ],
      "source": [
        "###################################\n",
        "model = ConvNet()\n",
        "#model=CustomCNN()\n",
        "#print(model)\n",
        "\n",
        "###################################\n",
        "criterion=nn.MSELoss()\n",
        "optimizer=t.optim.Adam(model.parameters(),lr=learning_rate)\n",
        "\n",
        "n_total_steps = len(train_data)\n",
        "\n",
        "###################################\n",
        "for epoch in range(epochs):\n",
        "\n",
        "    model.train()\n",
        "    running_loss=0.0\n",
        "\n",
        "    for i,(center,left,right,steering,thrust,reverse,speed) in enumerate(train_data):\n",
        "       \n",
        "        labels=t.cat((steering.unsqueeze(1),thrust.unsqueeze(1)),dim=1)    \n",
        "        outputs=model(center)\n",
        "        loss=criterion(outputs,labels)\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        running_loss+=loss.item()\n",
        "\n",
        "        print(f'[{epoch + 1}] loss: {running_loss / n_total_steps:.3f}')\n",
        "\n",
        "print('Finished Training')\n",
        "PATH = './final simulation/ARL-Workshop-23-DL-Project/model.pth'\n",
        "t.save(model, PATH)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[1] loss: 0.031\n",
            "[2] loss: 0.021\n",
            "[3] loss: 0.019\n",
            "[4] loss: 0.023\n",
            "[5] loss: 0.013\n",
            "[6] loss: 0.035\n",
            "[7] loss: 0.026\n",
            "[8] loss: 0.025\n"
          ]
        }
      ],
      "source": [
        "model.eval()\n",
        "with t.no_grad():\n",
        "    for i,(center,left,right,steering,thrust,reverse,speed) in enumerate(test_data):\n",
        "        labels=t.cat((steering.unsqueeze(1),thrust.unsqueeze(1)),dim=1)    \n",
        "        outputs=model(center)\n",
        "        loss=criterion(outputs,labels)\n",
        "\n",
        "        print(f'[{i + 1}] loss: {loss.item():.3f}')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3.9.12 ('base')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    },
    "vscode": {
      "interpreter": {
        "hash": "cf0b053ec60c51acbf9b234663d2a94147f1419af99fefc5982f553fc46997b4"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
